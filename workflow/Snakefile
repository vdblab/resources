import os
import sys

import pandas as pd

from pathlib import Path


refs = Path("references") / "sequences"
idxs = Path("references") / "indexes"
dbs = Path("dbs")
tax = Path("taxonomy")



MANIFEST = pd.read_csv(os.path.join(workflow.current_basedir, "references.txt"), sep=",").set_index("name", drop=False)
MANIFEST["base"]  =  MANIFEST.url.apply(lambda x: os.path.basename(x))
MANIFEST["output"] =  refs / MANIFEST["org"] / MANIFEST["name"] / MANIFEST["base"]

MANIFEST_dict = MANIFEST.to_dict('index')
print(MANIFEST)

def get_path(wildcards):
    return



default_container = "docker://ghcr.io/vdblab/utility:0b"


rule all:
    input:
        raw = expand(f"{refs}/{{org}}/{{name}}/{{base}}",  zip,
                  org=MANIFEST["org"], name=MANIFEST["name"], base=MANIFEST["base"])

rule getref:
    container: default_container
    output:
        f"{refs}/{{org}}/{{name}}/{{base}}",
    params:
        url=lambda wildcards: MANIFEST.loc[wildcards.name, "url"]
    shell:"""
    wget  {params.url} -O {output}
    """


#validate(
#    MANIFEST, os.path.join(workflow.current_basedir, "../schemas/manifest.schema.yaml")
#)






# db16S = multiext(f"{dbs}/ncbi16S/2022/16S_ribosomal_RNA", ".fna", ".ndb", ".nhr", ".nin", ".nnd", ".nni", ".nog", ".nos",  ".nsq",
#                  ".ntf", ".nto",  "_id_and_taxonomy.txt")


# adapters =  refs / "synthetic" / "stephenturner" / "adapters_combined_256_unique.fasta"

# metaphlan =  multiext("mpa_vJan21_CHOCOPhlAnSGB_202103", ".1.bt2l", ".2.bt2l", ".3.bt2l", ".4.bt2l", ".rev.1.bt2l", ".rev.2.bt2l")


# default_container = "docker://ghcr.io/vdblab/utility:0b"

# rule all:
#     input:
#         db16S,
#         adapters,
#         metaphlan,

# module references:
#     snakefile:
#         "rules/references.smk"


# use rule * from references as references_*


# module indexes:
#     snakefile:
#         "rules/indexes.smk"

# rule all:
#     input:
#         rules.references_all.input,
# #    default_target: True
